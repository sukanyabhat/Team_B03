closeAllConnections()
rm(list=ls())

library(forecast)
library(dplyr)



#Read data file 

godaddy <- read.table('student_data_20160418.txt',header = TRUE,sep='\t')##nrow(godaddy) 358666
godaddy[[1]] <- strptime(as.character(godaddy[[1]]), "%m/%d/%Y")##nrow(godaddy)

#Sampling
godaddy=subset(godaddy,godaddy[[1]]>"2012-12-31")##nrow(godaddy) 263681

godaddy$tot_row_flag=ifelse((godaddy[[2]]=='Total' | godaddy[[3]]=='Total' | godaddy[[4]]=='Total'),1,0)
godaddy$tot_1_flag=ifelse((godaddy[[2]]=='Total' & godaddy[[3]]!='Total' & godaddy[[4]]!='Total'),1,0)
godaddy$tot_2_flag=ifelse((godaddy[[2]]!='Total' & godaddy[[3]]=='Total' & godaddy[[4]]!='Total'),1,0)
godaddy$tot_3_flag=ifelse((godaddy[[2]]!='Total' & godaddy[[3]]!='Total' & godaddy[[4]]=='Total'),1,0)
godaddy$tot_1_2_flag=ifelse((godaddy[[2]]=='Total' & godaddy[[3]]=='Total' & godaddy[[4]]!='Total'),1,0)
godaddy$tot_2_3_flag=ifelse((godaddy[[2]]!='Total' & godaddy[[3]]=='Total' & godaddy[[4]]=='Total'),1,0)
godaddy$tot_1_3_flag=ifelse((godaddy[[2]]=='Total' & godaddy[[3]]!='Total' & godaddy[[4]]=='Total'),1,0)
godaddy$tot_1_2_3_flag=ifelse((godaddy[[2]]=='Total' & godaddy[[3]]=='Total' & godaddy[[4]]=='Total'),1,0)

godaddy_set_1=subset(godaddy,godaddy$tot_row_flag==0,select = c(1:(ncol(godaddy)-8)))##nrow(godaddy_set_1) 165728

#godaddy_set_2=subset(godaddy,godaddy$tot_1_flag==1,select = c(1,3:(ncol(godaddy)-8))) ##nrow(godaddy_set_2) 
godaddy_set_3=subset(godaddy,godaddy$tot_2_flag==1,select = c(1,2,4:(ncol(godaddy)-8))) ##nrow(godaddy_set_3) 68272
godaddy_set_4=subset(godaddy,godaddy$tot_3_flag==1,select = c(1:3,5:(ncol(godaddy)-8))) ##nrow(godaddy_set_4) 16048

# correct 5
godaddy_set_5=subset(godaddy,godaddy$tot_1_2_flag==1,select = c(1,4:(ncol(godaddy)-8))) ##nrow(godaddy_set_5) 12630
#godaddy_set_6=subset(godaddy,godaddy$tot_2_3_flag==1,select = c(1,2,5:(ncol(godaddy)-8))) ##nrow(godaddy_set_6) 
#godaddy_set_7=subset(godaddy,godaddy$tot_1_3_flag==1,select = c(1,3,5:(ncol(godaddy)-8))) ##nrow(godaddy_set_7) 

#ignore this set for now----need to come back to this
#godaddy_set_8=subset(godaddy,godaddy$tot_1_2_3_flag==1,select = c(1,5:(ncol(godaddy)-8))) ##nrow(godaddy_set_8) 1003

#165728+68272+16048+12630+1003


#Here we know that column 2,3,4 are dimension columns
sample_dimension_combinations=sample_n(unique(subset(godaddy,godaddy$tot_row_flag==0,select = c(2,3,4))),5)
#sample_sub_combinations_6=unique(subset(sample_dimension_combinations,select = c(1)))
#sample_sub_combinations_7=unique(subset(sample_dimension_combinations,select = c(2)))
sample_sub_combinations_5=unique(subset(sample_dimension_combinations,select = c(3)))
sample_sub_combinations_4=unique(subset(sample_dimension_combinations,select = c(1,2)))
#sample_sub_combinations_2=unique(subset(sample_dimension_combinations,select = c(2,3)))
sample_sub_combinations_3=unique(subset(sample_dimension_combinations,select = c(1,3)))

godaddy_set_1=merge(godaddy_set_1,sample_dimension_combinations)[, (names(godaddy_set_1))]
#godaddy_set_2=merge(godaddy_set_2,sample_sub_combinations_2)[,(names(godaddy_set_2))]
godaddy_set_3=merge(godaddy_set_3,sample_sub_combinations_3)[, (names(godaddy_set_3))]

godaddy_set_4=merge(godaddy_set_4,sample_sub_combinations_4)[, (names(godaddy_set_4))]
godaddy_set_5=merge(godaddy_set_5,sample_sub_combinations_5)[, (names(godaddy_set_5))]
#godaddy_set_6=merge(godaddy_set_6,sample_sub_combinations_6)[, (names(godaddy_set_6))]
#godaddy_set_7=merge(godaddy_set_7,sample_sub_combinations_7)[, (names(godaddy_set_7))]

#filling up missing rows
#temp fix, generally expect the missing dimensions to be filled with 0 values


grp=sample_dimension_combinations
date_list=unique(subset(godaddy,select = c(1)))
master_list=merge(date_list,grp)
master_list <- master_list[order(master_list[[1]], master_list[[2]], master_list[[3]], master_list[[4]]),]
godaddy_set_1=merge(godaddy_set_1,master_list,all.y = TRUE)
godaddy_set_1[,(ncol(master_list)+1):ncol(godaddy_set_1) ][is.na(godaddy_set_1[,(ncol(master_list)+1):ncol(godaddy_set_1)])]=0

# grp=sample_sub_combinations_2
# date_list=unique(subset(godaddy,select = c(1)))
# master_list=merge(date_list,grp)
# master_list <- master_list[order(master_list[[1]], master_list[[2]], master_list[[3]]),]
# godaddy_set_2=merge(godaddy_set_2,master_list,all.y = TRUE)
# godaddy_set_2[,(ncol(master_list)+1):ncol(godaddy_set_2) ][is.na(godaddy_set_2[,(ncol(master_list)+1):ncol(godaddy_set_2)])]=0

grp=sample_sub_combinations_3
date_list=unique(subset(godaddy,select = c(1)))
master_list=merge(date_list,grp)
master_list <- master_list[order(master_list[[1]], master_list[[2]], master_list[[3]]),]
godaddy_set_3=merge(godaddy_set_3,master_list,all.y = TRUE)
godaddy_set_3[,(ncol(master_list)+1):ncol(godaddy_set_3) ][is.na(godaddy_set_3[,(ncol(master_list)+1):ncol(godaddy_set_3)])]=0

grp=sample_sub_combinations_4
date_list=unique(subset(godaddy,select = c(1)))
master_list=merge(date_list,grp)
master_list <- master_list[order(master_list[[1]], master_list[[2]], master_list[[3]]),]
godaddy_set_4=merge(godaddy_set_4,master_list,all.y = TRUE)
godaddy_set_4[,(ncol(master_list)+1):ncol(godaddy_set_4) ][is.na(godaddy_set_4[,(ncol(master_list)+1):ncol(godaddy_set_4)])]=0

grp=sample_sub_combinations_5
date_list=unique(subset(godaddy,select = c(1)))
master_list=merge(date_list,grp)
master_list <- master_list[order(master_list[[1]], master_list[[2]]),]
godaddy_set_5=merge(godaddy_set_5,master_list,all.y = TRUE)
godaddy_set_5[,(ncol(master_list)+1):ncol(godaddy_set_5) ][is.na(godaddy_set_5[,(ncol(master_list)+1):ncol(godaddy_set_5)])]=0

# grp=sample_sub_combinations_6
# date_list=unique(subset(godaddy,select = c(1)))
# master_list=merge(date_list,grp)
# master_list <- master_list[order(master_list[[1]], master_list[[2]]),]
# godaddy_set_6=merge(godaddy_set_6,master_list,all.y = TRUE)
# godaddy_set_6[,(ncol(master_list)+1):ncol(godaddy_set_6) ][is.na(godaddy_set_6[,(ncol(master_list)+1):ncol(godaddy_set_6)])]=0
# 
# grp=sample_sub_combinations_7
# date_list=unique(subset(godaddy,select = c(1)))
# master_list=merge(date_list,grp)
# master_list <- master_list[order(master_list[[1]], master_list[[2]]),]
# godaddy_set_7=merge(godaddy_set_7,master_list,all.y = TRUE)
# godaddy_set_7[,(ncol(master_list)+1):ncol(godaddy_set_7) ][is.na(godaddy_set_7[,(ncol(master_list)+1):ncol(godaddy_set_7)])]=0



subset=c("godaddy_set_1","godaddy_set_2","godaddy_set_3","godaddy_set_4","godaddy_set_5","godaddy_set_6","godaddy_set_7","godaddy_set_8")
dimension_table=c("sample_dimension_combinations","sample_sub_combinations_2","sample_sub_combinations_3","sample_sub_combinations_4","sample_sub_combinations_5","sample_sub_combinations_6","sample_sub_combinations_7","sample_sub_combinations_8")
dimension_number=c(ncol(sample_dimension_combinations),2,2,ncol(sample_sub_combinations_4),ncol(sample_sub_combinations_5),1,1,0)


Xref_table=data.frame(subset,dimension_table,dimension_number)
Xref_table <<- Xref_table
Initial_date<<-"2015-09-01"


data_train=subset(godaddy_set_1,godaddy_set_1[[1]]<Initial_date)

metric_col_start=ncol(sample_dimension_combinations)+1
no_of_metric=ncol(godaddy_set_1)-(ncol(sample_dimension_combinations)+1)
dimension=sample_dimension_combinations

predictions=NULL
#j loop for remaining metrics
#head(time_series_data)
#prediction_func=function(data_train,metric_col_start,dimension,no_of_metric){
for (j in 1:no_of_metric){
  for(i in 1:nrow(dimension)){
    time_series_data=merge(data_train,dimension[i,])[, names(data_train)]
    
    time_series_data=subset(time_series_data[order(time_series_data[[1]]),],select=c(metric_col_start+j))
    
    #order by date
    if (mean(time_series_data[[1]]) == 0)
      next
    if (dim(time_series_data)[1] < 30)
      next
    #need to think if this helps or not
    
    #find outliers and the best replacement values
    g<-data.frame(tsoutliers(time_series_data[[1]]))
    #replace
    time_series_data[g$index,1]=g$replacements
    #convert to time series , units of 7 days
    
    time_series_data=ts(time_series_data,frequency = 7)
    #next day prediction
    pred_arima=forecast(auto.arima(time_series_data,approximation=TRUE),h=1)
    #absolute prediction
    abs_pred<-pred_arima$mean[1]
    #lower threshold
    prediction_min<-pred_arima$lower[2]
    #upper threshold
    prediction_max<-pred_arima$upper[2]
    
    
    
    #combine with old predictions
    predictions=rbind(predictions,cbind(colnames(data_train)[metric_col_start+j],toString(data_train[nrow(data_train),1]+ as.difftime(1, unit="days")),dimension[i,],prediction_min,abs_pred,prediction_max))
  }
}

write.table(predictions,file = paste("Threshold_Initial_", "godaddy_set_1", ".csv",sep = ""),row.names = F, sep=",",  col.names=FALSE)
#####################################################################################################################









data_train=subset(godaddy_set_3,godaddy_set_3[[1]]<Initial_date)

metric_col_start=ncol(sample_sub_combinations_3)+1
no_of_metric=ncol(godaddy_set_3)-(ncol(sample_sub_combinations_3)+1)
dimension=sample_sub_combinations_3

predictions=NULL
#j loop for remaining metrics
#head(time_series_data)
#prediction_func=function(data_train,metric_col_start,dimension,no_of_metric){
for (j in 1:no_of_metric){
  for(i in 1:nrow(dimension)){
    time_series_data=merge(data_train,dimension[i,])[, names(data_train)]
    
    time_series_data=subset(time_series_data[order(time_series_data[[1]]),],select=c(metric_col_start+j))
    
    #order by date
    if (mean(time_series_data[[1]]) == 0)
      next
    if (dim(time_series_data)[1] < 30)
      next
    #need to think if this helps or not
    
    #find outliers and the best replacement values
    g<-data.frame(tsoutliers(time_series_data[[1]]))
    #replace
    time_series_data[g$index,1]=g$replacements
    #convert to time series , units of 7 days
    
    time_series_data=ts(time_series_data,frequency = 7)
    #next day prediction
    pred_arima=forecast(auto.arima(time_series_data,approximation=TRUE),h=1)
    #absolute prediction
    abs_pred<-pred_arima$mean[1]
    #lower threshold
    prediction_min<-pred_arima$lower[2]
    #upper threshold
    prediction_max<-pred_arima$upper[2]
    
    
    
    #combine with old predictions
    predictions=rbind(predictions,cbind(colnames(data_train)[metric_col_start+j],toString(data_train[nrow(data_train),1]+ as.difftime(1, unit="days")),dimension[i,],prediction_min,abs_pred,prediction_max))
  }
}

write.table(predictions,file = paste("Threshold_Initial_", "godaddy_set_3", ".csv",sep = ""),row.names = F, sep=",",  col.names=FALSE)
########################################################################################################################3

data_train=subset(godaddy_set_4,godaddy_set_4[[1]]<Initial_date)

metric_col_start=ncol(sample_sub_combinations_4)+1
no_of_metric=ncol(godaddy_set_4)-(ncol(sample_sub_combinations_4)+1)
dimension=sample_sub_combinations_4

predictions=NULL
#j loop for remaining metrics
#head(time_series_data)
#prediction_func=function(data_train,metric_col_start,dimension,no_of_metric){
for (j in 1:no_of_metric){
  for(i in 1:nrow(dimension)){
    time_series_data=merge(data_train,dimension[i,])[, names(data_train)]
    
    time_series_data=subset(time_series_data[order(time_series_data[[1]]),],select=c(metric_col_start+j))
    
    #order by date
    if (mean(time_series_data[[1]]) == 0)
      next
    if (dim(time_series_data)[1] < 30)
      next
    #need to think if this helps or not
    
    #find outliers and the best replacement values
    g<-data.frame(tsoutliers(time_series_data[[1]]))
    #replace
    time_series_data[g$index,1]=g$replacements
    #convert to time series , units of 7 days
    
    time_series_data=ts(time_series_data,frequency = 7)
    #next day prediction
    pred_arima=forecast(auto.arima(time_series_data,approximation=TRUE),h=1)
    #absolute prediction
    abs_pred<-pred_arima$mean[1]
    #lower threshold
    prediction_min<-pred_arima$lower[2]
    #upper threshold
    prediction_max<-pred_arima$upper[2]
    
    
    
    #combine with old predictions
    predictions=rbind(predictions,cbind(colnames(data_train)[metric_col_start+j],toString(data_train[nrow(data_train),1]+ as.difftime(1, unit="days")),dimension[i,],prediction_min,abs_pred,prediction_max))
  }
}

write.table(predictions,file = paste("Threshold_Initial_", "godaddy_set_4", ".csv",sep = ""),row.names = F, sep=",",  col.names=FALSE)



###########################################################################################################



data_train=subset(godaddy_set_5,godaddy_set_5[[1]]<Initial_date)

metric_col_start=ncol(sample_sub_combinations_5)+1
no_of_metric=ncol(godaddy_set_5)-(ncol(sample_sub_combinations_5)+1)
dimension=data.frame(sample_sub_combinations_5)

predictions=NULL
#j loop for remaining metrics
#head(time_series_data)
#prediction_func=function(data_train,metric_col_start,dimension,no_of_metric){
for (j in 1:no_of_metric){
  for(i in 1:nrow(dimension)){
    time_series_data=merge(data_train,dimension[i,,drop=FALSE])[, names(data_train)]
    
    time_series_data=subset(time_series_data[order(time_series_data[[1]]),],select=c(metric_col_start+j))
    length(time_series_data$X_u1.gcr==0)
    #order by date
    if (mean(time_series_data[[1]]) == 0)
      next
    if (dim(time_series_data)[1] < 30)
      next
    #need to think if this helps or not
    
    #find outliers and the best replacement values
    g<-data.frame(tsoutliers(time_series_data[[1]]))
    #replace
    time_series_data[g$index,1]=g$replacements
    #convert to time series , units of 7 days
    
    time_series_data=ts(time_series_data,frequency = 7)
    #next day prediction
    pred_arima=forecast(auto.arima(time_series_data,approximation=TRUE),h=1)
    #absolute prediction
    abs_pred<-pred_arima$mean[1]
    #lower threshold
    prediction_min<-pred_arima$lower[2]
    #upper threshold
    prediction_max<-pred_arima$upper[2]
    
    
    
    #combine with old predictions
    predictions=rbind(predictions,cbind(colnames(data_train)[metric_col_start+j],toString(data_train[nrow(data_train),1]+ as.difftime(1, unit="days")),dimension[i,],prediction_min,abs_pred,prediction_max))
  }
}

write.table(predictions,file = paste("Threshold_Initial_", "godaddy_set_5", ".csv",sep = ""),row.names = F, sep=",",  col.names=FALSE)

#########################################################################################################################


Anomaly_Detection=function(data){
dimension_number=Xref_table$dimension_number[Xref_table$subset==deparse(substitute(data))]
#dimension_number=Xref_table$dimension_number[Xref_table$subset=="godaddy_set_1"]


#Read Initial prediction file 

#initial_pred <- read.csv(paste("Threshold_Initial_","godaddy_set_1",".csv",sep = ""),header = FALSE)
initial_pred <- read.csv(paste("Threshold_Initial_",deparse(substitute(data)),".csv",sep = ""),header = FALSE)

initial_pred[[2]] <- strptime(as.character(initial_pred[[2]]), "%Y-%m-%d")
anomalies=NULL
for (j in (dimension_number+2):ncol(data)){
#Check metric
  
initial_prediction =subset(initial_pred,initial_pred[[1]]==colnames(data)[j],select=c(2:ncol(initial_pred)))

#get the current date observed values
godaddy_current_data_set=subset(data,data[[1]]==unique(initial_prediction[[1]]))

#join with predictions to check where the metric is less than predicted
merged=merge(godaddy_current_data_set,initial_prediction,by.x = c(1:(dimension_number+1)),by.y  = c(1:(dimension_number+1)))

anomalies_new=subset(merged, merged[,j]<merged[,(ncol(merged)-2)])
if(nrow(anomalies_new)>0){
anomalies_new$anomaly_metric=colnames(anomalies_new)[j]
anomalies_new$anomaly_flag=1
anomalies=rbind(anomalies,anomalies_new)}
}
#write.csv(anomalies,file = paste("Anomalies_", deparse(substitute(data)), ".csv",sep = ""),row.names = F)
return(anomalies)
}

##########################################################################################################################################################
anomalies_set_1=Anomaly_Detection(godaddy_set_1)
#anomalies_set_2=Anomaly_Detection(godaddy_set_2)
anomalies_set_3=Anomaly_Detection(godaddy_set_3)
anomalies_set_4=Anomaly_Detection(godaddy_set_4)
anomalies_set_5=Anomaly_Detection(godaddy_set_5)
#anomalies_set_6=Anomaly_Detection(godaddy_set_6)
#anomalies_set_7=Anomaly_Detection(godaddy_set_7)
#anomalies_set_8=Anomaly_Detection(godaddy_set_8)

######################################################################################################

#Prediction function

Prediction=function(data,date){
  
  
  data_train=subset(data,data[[1]]<=date)
  
  dimension_number=Xref_table$dimension_number[Xref_table$subset==deparse(substitute(data))]
  dimension_table=Xref_table$dimension_table[Xref_table$subset==deparse(substitute(data))]
  
  metric_col_start=dimension_number+1
  no_of_metric=ncol(data)-(dimension_number+1)
  dimension=data.frame(dimension_table)
  
  predictions=NULL
  #j loop for remaining metrics
  #head(time_series_data)
  #prediction_func=function(data_train,metric_col_start,dimension,no_of_metric){
  for (j in 1:no_of_metric){
    for(i in 1:nrow(dimension)){
      time_series_data=merge(data_train,dimension[i,,drop=FALSE])[, names(data_train)]
      
      time_series_data=subset(time_series_data[order(time_series_data[[1]]),],select=c(metric_col_start+j))
      #order by date
      if (mean(time_series_data[[1]]) == 0)
        next
      if (dim(time_series_data)[1] < 30)
        next
      #need to think if this helps or not
      
      #find outliers and the best replacement values
      g<-data.frame(tsoutliers(time_series_data[[1]]))
      #replace
      time_series_data[g$index,1]=g$replacements
      #convert to time series , units of 7 days
      
      time_series_data=ts(time_series_data,frequency = 7)
      #next day prediction
      pred_arima=forecast(auto.arima(time_series_data,approximation=TRUE),h=1)
      #absolute prediction
      abs_pred<-pred_arima$mean[1]
      #lower threshold
      prediction_min<-pred_arima$lower[2]
      #upper threshold
      prediction_max<-pred_arima$upper[2]
      
      
      
      #combine with old predictions
      predictions=rbind(predictions,cbind(colnames(data_train)[metric_col_start+j],toString(data_train[nrow(data_train),1]+ as.difftime(1, unit="days")),dimension[i,],prediction_min,abs_pred,prediction_max))
    }
  }
  
return(predictions)
}


date_list=unique(subset(godaddy[order(godaddy[[1]]),],godaddy[[1]]>=Initial_date,select = c(1)))

date=1
